# è‚¡ç¥¨ä¿¡æ¯æŸ¥è¯¢åº”ç”¨
# æ³¨æ„ï¼šä½¿ç”¨æ­¤ä»£ç ä¼šäº§ç”ŸOpenAI APIè´¹ç”¨
# è‹¥ä¸æƒ³äº§ç”Ÿè´¹ç”¨ï¼Œè¯·æ›´æ¢ä¸ºå…¶ä»–LLMæ¨¡å‹

# ----------------------------
# å¯¼å…¥æ‰€éœ€åº“ï¼ˆæŒ‰åŠŸèƒ½åˆ†ç»„ï¼‰
# ----------------------------
# Webåº”ç”¨æ¡†æ¶
import streamlit as st
# æ•°æ®å¤„ç†
import pandas as pd
# å›¾åƒå¤„ç†
from PIL import Image
# è‚¡ç¥¨æ•°æ®è·å–
import yfinance as yf
from yahooquery import Ticker
# æ—¥æœŸå¤„ç†
from datetime import datetime, timedelta
# EDGARæ•°æ®åº“ï¼ˆç¾å›½SEC filingsï¼‰
from edgar import Company, TXTML
# ç¯å¢ƒå˜é‡ç®¡ç†
from dotenv import load_dotenv
import os
# LangChainç›¸å…³ï¼ˆç”¨äºAIé—®ç­”å’Œæ–‡æ¡£å¤„ç†ï¼‰
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.chains.summarize import load_summarize_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter, PythonCodeTextSplitter


# ----------------------------
# åˆå§‹åŒ–é…ç½®
# ----------------------------
# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆåŒ…å«APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯ï¼‰
load_dotenv()
# è·å–OpenAI APIå¯†é’¥
openai_api_key = os.getenv("OPENAI_API_KEY")


# ----------------------------
# å·¥å…·å‡½æ•°
# ----------------------------
def format_large_number(num):
    """
    å°†å¤§é¢æ•°å­—æ ¼å¼åŒ–ä¸ºæ˜“è¯»å½¢å¼ï¼ˆä¸‡äº¿ã€åäº¿ã€ç™¾ä¸‡ç­‰ï¼‰
    
    å‚æ•°:
        num: éœ€è¦æ ¼å¼åŒ–çš„æ•°å­—
        
    è¿”å›:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼ˆå¦‚"$1.23B"è¡¨ç¤º12.3äº¿ç¾å…ƒï¼‰
    """
    if abs(num) >= 1_000_000_000_000:  # ä¸‡äº¿çº§åˆ«
        return f"${num / 1_000_000_000_000:.2f}T"
    elif abs(num) >= 1_000_000_000:  # åäº¿çº§åˆ«
        return f"${num / 1_000_000_000:.2f}B"
    elif abs(num) >= 1_000_000:  # ç™¾ä¸‡çº§åˆ«
        return f"${num / 1_000_000:.2f}M"
    else:  # å…¶ä»–è¾ƒå°æ•°å­—
        return str(num)


# ----------------------------
# è‚¡ç¥¨æ•°æ®å­—å…¸
# åŒ…å«æ”¯æŒæŸ¥è¯¢çš„è‚¡ç¥¨ä¿¡æ¯ï¼šå…¬å¸åç§°ã€è‚¡ç¥¨ä»£ç ã€SECçš„CIKç¼–å·ï¼ˆç”¨äºè·å–è´¢æŠ¥ï¼‰
# ----------------------------
stocks = {
    "Apple - 'AAPL'": {
        "name": "APPLE INC", 
        "symbol": "AAPL", 
        "cik": "0000320193"  # CIK: ç¾å›½SECåˆ†é…çš„å…¬å¸å”¯ä¸€æ ‡è¯†
    },
    "Alphabet - 'GOOG'": {
        "name": "Alphabet Inc.", 
        "symbol": "GOOG", 
        "cik": "0001652044"
    },
    "Facebook - 'META'": {
        "name": "META PLATFORMS INC", 
        "symbol": "META", 
        "cik": "0001326801"
    },
    "Amazon - 'AMZN'": {
        "name": "AMAZON COM INC", 
        "symbol": "AMZN", 
        "cik": "0001018724"
    },
    "Netflix - 'NFLX'": {
        "name": "NETFLIX INC", 
        "symbol": "NFLX", 
        "cik": "0001065280"
    },
    "Microsoft - 'MSFT'": {
        "name": "MICROSOFT CORP", 
        "symbol": "MSFT", 
        "cik": "0000789019"
    },
    "Tesla - 'TSLA'": {
        "name": "TESLA INC", 
        "symbol": "TSLA", 
        "cik": "0001318605"
    },
}


# ----------------------------
# AIåˆ†æå‡½æ•°
# ----------------------------
def get_recommendation(stock_info, question):
    """
    åŸºäºå…¬å¸10-Kè´¢æŠ¥æ–‡æ¡£ï¼Œä½¿ç”¨AIå›ç­”å…³äºå…¬å¸çš„é—®é¢˜
    
    å‚æ•°:
        stock_info: è‚¡ç¥¨ä¿¡æ¯å­—å…¸ï¼ˆåŒ…å«å…¬å¸åç§°ã€CIKç­‰ï¼‰
        question: éœ€è¦AIå›ç­”çš„é—®é¢˜
        
    è¿”å›:
        AIç”Ÿæˆçš„å›ç­”ï¼ˆå·²ç§»é™¤Markdownæ ¼å¼ç¬¦å·ï¼‰
    """
    # 1. ä»EDGARæ•°æ®åº“è·å–å…¬å¸10-Kå¹´æŠ¥ï¼ˆç¾å›½ä¸Šå¸‚å…¬å¸å¹´åº¦æŠ¥å‘Šï¼‰
    company = Company(stock_info["name"], stock_info["cik"])
    doc = company.get_10K()  # è·å–æœ€æ–°10-Kæ–‡æ¡£
    text = TXTML.parse_full_10K(doc)  # è§£ææ–‡æ¡£ä¸ºçº¯æ–‡æœ¬
    
    # 2. åˆå§‹åŒ–OpenAIå¤§è¯­è¨€æ¨¡å‹ï¼ˆæ¸©åº¦å‚æ•°æ§åˆ¶è¾“å‡ºéšæœºæ€§ï¼Œ0.15è¡¨ç¤ºè¾ƒä½éšæœºæ€§ï¼‰
    llm = OpenAI(temperature=0.15, openai_api_key=openai_api_key)
    
    # 3. å¤„ç†æ–‡æœ¬ï¼šå–æ–‡æ¡£ä¸­é—´ä¸‰åˆ†ä¹‹ä¸€å†…å®¹ï¼ˆé¿å…æ–‡æ¡£è¿‡é•¿å¯¼è‡´å¤„ç†ç¼“æ…¢ï¼‰
    third_length = int(len(text) / 3)
    two_thirds_length = int(third_length * 2)
    text_segment = text[third_length:two_thirds_length]  # å–ä¸­é—´éƒ¨åˆ†
    
    # 4. åˆ†å‰²æ–‡æœ¬ï¼šå°†é•¿æ–‡æœ¬åˆ†æˆé€‚åˆæ¨¡å‹å¤„ç†çš„å°å—
    text_splitter = PythonCodeTextSplitter(
        chunk_size=3000,    # æ¯ä¸ªæ–‡æœ¬å—çš„å¤§å°
        chunk_overlap=300   # å—ä¹‹é—´çš„é‡å éƒ¨åˆ†ï¼ˆä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼‰
    )
    docs = text_splitter.create_documents([text_segment])  # åˆ›å»ºæ–‡æ¡£å¯¹è±¡åˆ—è¡¨
    
    # 5. åˆ›å»ºæ–‡æœ¬åµŒå…¥ï¼ˆå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œç”¨äºåç»­æ£€ç´¢ï¼‰
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    
    # 6. æ„å»ºå‘é‡æ•°æ®åº“ï¼ˆç”¨äºé«˜æ•ˆæ£€ç´¢ç›¸å…³æ–‡æœ¬ç‰‡æ®µï¼‰
    docsearch = FAISS.from_documents(docs, embeddings)
    
    # 7. åˆ›å»ºæ£€ç´¢å¼é—®ç­”é“¾ï¼ˆç»“åˆæ£€ç´¢å’ŒLLMç”Ÿæˆå›ç­”ï¼‰
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",  # å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£"å¡«å……"åˆ°æç¤ºä¸­
        retriever=docsearch.as_retriever()  # æ£€ç´¢å™¨
    )
    
    # 8. æ‰§è¡ŒæŸ¥è¯¢å¹¶è¿”å›ç»“æœï¼ˆç§»é™¤Markdownæ ¼å¼ç¬¦å·ï¼‰
    analysis = qa_chain.run(question)
    return analysis.translate(str.maketrans("", "", "_*"))  # ç§»é™¤ä¸‹åˆ’çº¿å’Œæ˜Ÿå·


# ----------------------------
# Streamlité¡µé¢å¸ƒå±€ä¸å†…å®¹
# ----------------------------
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Stock Information",  # é¡µé¢æ ‡é¢˜
    layout="wide",  # å®½å¸ƒå±€
    initial_sidebar_state="collapsed",  # åˆå§‹ä¾§è¾¹æ çŠ¶æ€
    page_icon="Color Logo.png"  # é¡µé¢å›¾æ ‡ï¼ˆéœ€ç¡®ä¿è¯¥æ–‡ä»¶å­˜åœ¨ï¼‰
)

# åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼ˆå·¦ä¾§çª„åˆ—ï¼šæ•°æ®å±•ç¤ºï¼›å³ä¾§å®½åˆ—ï¼šè¯¦ç»†ä¿¡æ¯ï¼‰
col1, col2 = st.columns((1, 3))

# å·¦ä¾§åˆ—ï¼šæ˜¾ç¤ºlogoå’Œè‚¡ç¥¨é€‰æ‹©å™¨
with col1:
    # æ˜¾ç¤ºåº”ç”¨logo
    try:
        icon = Image.open("Colour Logo.png")  # å°è¯•æ‰“å¼€logoå›¾ç‰‡
        col1.image(icon, width=100)
    except FileNotFoundError:
        st.warning("Logoå›¾ç‰‡æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æ ‡é¢˜")
        st.subheader("Stock Analyzer")
    
    # è‚¡ç¥¨é€‰æ‹©ä¸‹æ‹‰æ¡†
    selected_stock = col1.selectbox(
        "é€‰æ‹©è‚¡ç¥¨", 
        options=list(stocks.keys()), 
        index=0  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆAppleï¼‰
    )


# ----------------------------
# è·å–å¹¶å±•ç¤ºè‚¡ç¥¨æ•°æ®
# ----------------------------
# è·å–é€‰ä¸­è‚¡ç¥¨çš„ä¿¡æ¯
selected_stock_info = stocks[selected_stock]

# 1. è‚¡ç¥¨å†å²ä»·æ ¼ï¼ˆä½¿ç”¨yfinanceï¼‰
with col1:
    # åˆå§‹åŒ–yfinanceçš„tickerå¯¹è±¡
    yf_ticker = yf.Ticker(selected_stock_info["symbol"])
    
    # è®¡ç®—æ—¶é—´èŒƒå›´ï¼ˆè¿‘360å¤©ï¼‰
    end_date = datetime.now()
    start_date = end_date - timedelta(days=360)
    
    # è·å–å†å²æ•°æ®å¹¶æå–æ”¶ç›˜ä»·
    historical_data = yf_ticker.history(start=start_date, end=end_date)
    closing_prices = historical_data["Close"]
    
    # ç»˜åˆ¶æ”¶ç›˜ä»·æŠ˜çº¿å›¾
    st.subheader("è¿‘1å¹´æ”¶ç›˜ä»·èµ°åŠ¿")
    col1.line_chart(closing_prices, use_container_width=True)


# 2. å…¬å¸æ¦‚è¿°
with col2:
    st.title("å…¬å¸æ¦‚è¿°")
    # è·å–å…¬å¸ä¸šåŠ¡æ‘˜è¦å¹¶æ˜¾ç¤º
    company_summary = yf_ticker.info.get("longBusinessSummary", "æš‚æ— å…¬å¸æ¦‚è¿°ä¿¡æ¯")
    col2.write(company_summary)


# 3. å¹´åº¦è´¢åŠ¡æ•°æ®ï¼ˆæ”¶å…¥å’Œæ”¶ç›Šï¼‰
with col1:
    st.subheader("å¹´åº¦è´¢åŠ¡æ‘˜è¦")
    # ä½¿ç”¨yahooqueryè·å–è´¢åŠ¡æ•°æ®
    yq_ticker = Ticker(selected_stock_info["symbol"])
    earnings_data = yq_ticker.earnings  # è·å–æ”¶ç›Šæ•°æ®
    
    # æå–å¹´åº¦è´¢åŠ¡å›¾è¡¨æ•°æ®
    financials_data = earnings_data[selected_stock_info["symbol"]]['financialsChart']['yearly']
    
    # è½¬æ¢ä¸ºDataFrameå¹¶æ ¼å¼åŒ–
    df_financials = pd.DataFrame(financials_data)
    df_financials = df_financials.rename(
        columns={'earnings': 'å¹´åº¦æ”¶ç›Š', 'revenue': 'å¹´åº¦æ”¶å…¥', 'date': 'å¹´ä»½'}
    )
    
    # æ ¼å¼åŒ–æ•°å€¼åˆ—ï¼ˆè½¬æ¢ä¸ºæ˜“è¯»æ ¼å¼ï¼‰
    numeric_cols = ['å¹´åº¦æ”¶ç›Š', 'å¹´åº¦æ”¶å…¥']
    df_financials[numeric_cols] = df_financials[numeric_cols].applymap(format_large_number)
    
    # å¤„ç†æ—¥æœŸåˆ—å¹¶è®¾ç½®ç´¢å¼•
    df_financials['å¹´ä»½'] = df_financials['å¹´ä»½'].astype(str)
    df_financials.set_index('å¹´ä»½', inplace=True)
    
    # æ˜¾ç¤ºè´¢åŠ¡æ•°æ®è¡¨æ ¼
    col1.dataframe(df_financials, use_container_width=True)


# 4. å…³é”®è‚¡ç¥¨æŒ‡æ ‡
with col1:
    st.subheader("å…³é”®æŒ‡æ ‡")
    # è·å–è¯¦ç»†æ‘˜è¦æ•°æ®
    summary_detail = yq_ticker.summary_detail[selected_stock_info["symbol"]]
    
    # æå–å¹¶æ ¼å¼åŒ–å„é¡¹æŒ‡æ ‡
    stock_metrics = {
        "å¸‚ç›ˆç‡ (P/E)": f'{summary_detail.get("trailingPE", "N/A"):.2f}' if summary_detail.get("trailingPE") else "N/A",
        "52å‘¨æœ€ä½ä»·": summary_detail.get("fiftyTwoWeekLow", "N/A"),
        "52å‘¨æœ€é«˜ä»·": summary_detail.get("fiftyTwoWeekHigh", "N/A"),
        "å¸‚å€¼": format_large_number(summary_detail.get("marketCap", 0)),
        "EBITDA": format_large_number(yf_ticker.info.get("ebitda", 0)),
        "ç›®æ ‡é«˜ä»·": yf_ticker.info.get("targetHighPrice", "N/A"),
        "æŠ•èµ„å»ºè®®": yf_ticker.info.get("recommendationKey", "N/A").upper()
    }
    
    # æ˜¾ç¤ºå„é¡¹æŒ‡æ ‡
    for metric, value in stock_metrics.items():
        col1.write(f"**{metric}**: {value}")


# ----------------------------
# AIåˆ†æç»“æœå±•ç¤º
# ----------------------------
st.title("Lucidate ç ”ç©¶æ¼”ç¤º (åŸºäºLangChain ğŸ¦œğŸ”—)")

with col2:
    st.subheader("æŠ•èµ„è€…å…³æ³¨ç‚¹åˆ†æ")
    
    # æ˜¾ç¤ºAIå¯¹ä¸‰ä¸ªå…³é”®é—®é¢˜çš„åˆ†æ
    st.write("**1. å…¬å¸ä¸»è¦äº§å“å’ŒæœåŠ¡æ˜¯ä»€ä¹ˆï¼Ÿ**")
    st.write(get_recommendation(selected_stock_info, "What are this firm's key products and services?"))
    
    st.write("\n**2. å…¬å¸çš„æ–°äº§å“ã€å¢é•¿æœºä¼šå’Œç‹¬ç‰¹ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ**")
    st.write(get_recommendation(
        selected_stock_info, 
        "What are the new products and growth opportunities for this firm. What are its unique strengths?"
    ))
    
    st.write("\n**3. å…¬å¸çš„ä¸»è¦ç«äº‰å¯¹æ‰‹å’Œé¢ä¸´çš„å¨èƒæ˜¯ä»€ä¹ˆï¼Ÿ**")
    st.write(get_recommendation(
        selected_stock_info, 
        "Who are this firms key competitors? What are the principal threats?"
    ))
